{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9ae7237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6t/cpjtlkn10wv603vnph9nr3sh0000gn/T/ipykernel_39429/3224924207.py:80: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  f_traErgsseccmA=np.array([np.array(f_tra0.ErgsseccmA),np.array(f_tra1.ErgsseccmA),np.array(f_tra2.ErgsseccmA),np.array(f_tra3.ErgsseccmA),np.array(f_tra4.ErgsseccmA),np.array(f_tra5.ErgsseccmA),np.array(f_tra6.ErgsseccmA),np.array(f_tra7.ErgsseccmA),np.array(f_tra8.ErgsseccmA),np.array(f_tra9.ErgsseccmA),np.array(f_tra10.ErgsseccmA),np.array(f_tra11.ErgsseccmA),np.array(f_tra12.ErgsseccmA),np.array(f_tra13.ErgsseccmA),np.array(f_tra14.ErgsseccmA),np.array(f_tra15.ErgsseccmA)])\n",
      "/var/folders/6t/cpjtlkn10wv603vnph9nr3sh0000gn/T/ipykernel_39429/3224924207.py:82: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  f_traAng=np.array([np.array(f_tra0.Angstroem / 10000),np.array(f_tra1.Angstroem / 10000),np.array(f_tra2.Angstroem / 10000),np.array(f_tra3.Angstroem / 10000),np.array(f_tra4.Angstroem / 10000),np.array(f_tra5.Angstroem / 10000),np.array(f_tra6.Angstroem / 10000),np.array(f_tra7.Angstroem / 10000),np.array(f_tra8.Angstroem / 10000),np.array(f_tra9.Angstroem / 10000),np.array(f_tra10.Angstroem / 10000),np.array(f_tra11.Angstroem / 10000),np.array(f_tra12.Angstroem / 10000),np.array(f_tra13.Angstroem / 10000),np.array(f_tra14.Angstroem / 10000),np.array(f_tra15.Angstroem / 10000)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "\n",
    "#modern earth albedo file\n",
    "absor1 = pd.read_csv('/Users/huihaoz/Downloads/GeometricA_Earth_HighCloud_UltraRes1.dat', comment = '#', delimiter='\\s+')\n",
    "\n",
    "#suitable planets\n",
    "pts=pd.read_csv('/Users/huihaoz/Downloads/PT_PES.txt', sep=',')\n",
    "\n",
    "#define the tempuratre of them\n",
    "pts[\"Teq\"] = (pts.STK * ((pts.SRadiusSun *  const.R_sun/(2*pts.SMAAU * const.au)))**(1/2) * (1-0.3)**(0.25))\n",
    "pts.iloc[0,8]=181.7\n",
    "pts.iloc[3,8]=351\n",
    "pts.iloc[9,8]=468\n",
    "pts.iloc[11,8]=301\n",
    "\n",
    "# Normalization of albedo\n",
    "# Split a Python List into Chunks using For Loops\n",
    "our_list = np.array(absor1.albH2O[:1079300])\n",
    "chunked_list = list()\n",
    "chunk_size = 251*2*5\n",
    "for i in range(0, len(our_list), chunk_size):\n",
    "    chunked_list.append(our_list[i:i+chunk_size])\n",
    "    \n",
    "our_listwl = np.array(absor1.nm[:1079300] / 1000)\n",
    "chunked_listwl = list()\n",
    "chunk_sizewl = 251*2*5\n",
    "for i in range(0, len(our_listwl), chunk_sizewl):\n",
    "    chunked_listwl.append(our_listwl[i:i+chunk_sizewl])\n",
    "    \n",
    "y_fit_index = np.linspace(0,429,430,dtype = int)\n",
    "wl_fit_index = [np.argmax(chunked_list[i]) for i in y_fit_index] #just for check\n",
    "\n",
    "pn_fit_non = [max(chunked_list[i]) for i in y_fit_index]\n",
    "wl_fit_non = [chunked_listwl[i][np.argmax(chunked_list[i])] for i in y_fit_index]\n",
    "alb_nogas = np.interp(absor1.nm/1000,wl_fit_non,np.array(pn_fit_non))\n",
    "wl_um2 = np.array(absor1.nm[:1079300])/1000 * u.um\n",
    "my_list_norabd = (absor1.totalb / alb_nogas) #normalized abd\n",
    "\n",
    "# Iterate over the list and replace any value greater than 1 with 1\n",
    "for i in range(len(my_list_norabd)):\n",
    "    if my_list_norabd[i] > 1:\n",
    "        my_list_norabd[i] = 1\n",
    "        \n",
    "#balckbody for target planets with normalzed abd\n",
    "tbd_planet=[]\n",
    "\n",
    "for i in range(len(pts.Teq)):\n",
    "    tbd_planet.append(np.array(my_list_norabd[:1079300]) * 2 * const.h *const.c**2 / ((wl_um2)**5 * (np.e**(const.c * const.h / (wl_um2 *const.k_B * pts.Teq[i] * u.K)) - 1)))\n",
    "\n",
    "#distance\n",
    "dis_2 = pts.DistancePC* const.pc\n",
    "\n",
    "#rad\n",
    "d_s_2 = pts.RadiusEar * const.R_earth\n",
    "\n",
    "#solid angle =  pi * r^2 / D^2\n",
    "ste = (d_s_2**2 * np.pi / dis_2**2)\n",
    "tbd_planet_earth = []\n",
    "for i in range(len(tbd_planet)):\n",
    "    tbd_planet_earth.append((tbd_planet[i] * ste[i]).to(u.erg/(u.s * u.cm**2 * u.um)))\n",
    "\n",
    "Flux_tbd_planet_earth =[]\n",
    "for i in range(len(tbd_planet_earth)):\n",
    "    Flux_tbd_planet_earth.append((tbd_planet_earth[i][1:] * np.diff(wl_um2)).to(u.W/u.m**2))\n",
    "\n",
    "#load the star flux model\n",
    "f_tra0 = pd.read_csv('/Users/huihaoz/Downloads/lte030.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra1 = pd.read_csv('/Users/huihaoz/Downloads/lte030.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra2 = pd.read_csv('/Users/huihaoz/Downloads/lte036.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra3 = pd.read_csv('/Users/huihaoz/Downloads/lte035.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra4 = pd.read_csv('/Users/huihaoz/Downloads/lte034.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra5 = pd.read_csv('/Users/huihaoz/Downloads/lte037.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra6 = pd.read_csv('/Users/huihaoz/Downloads/lte035.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra7 = pd.read_csv('/Users/huihaoz/Downloads/lte034.0-4.5-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra8 = pd.read_csv('/Users/huihaoz/Downloads/lte030.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra9 = pd.read_csv('/Users/huihaoz/Downloads/lte037.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra10 = pd.read_csv('/Users/huihaoz/Downloads/lte029.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra11 = pd.read_csv('/Users/huihaoz/Downloads/lte032.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra12 = pd.read_csv('/Users/huihaoz/Downloads/lte029.0-5.5-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra13 = pd.read_csv('/Users/huihaoz/Downloads/lte033.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra14 = pd.read_csv('/Users/huihaoz/Downloads/lte026.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_tra15 = pd.read_csv('/Users/huihaoz/Downloads/lte026.0-5.0-0.0a+0.0.BT-Settl.spec.7.txt', comment = '#', delimiter='\\s+')\n",
    "f_traErgsseccmA=np.array([np.array(f_tra0.ErgsseccmA),np.array(f_tra1.ErgsseccmA),np.array(f_tra2.ErgsseccmA),np.array(f_tra3.ErgsseccmA),np.array(f_tra4.ErgsseccmA),np.array(f_tra5.ErgsseccmA),np.array(f_tra6.ErgsseccmA),np.array(f_tra7.ErgsseccmA),np.array(f_tra8.ErgsseccmA),np.array(f_tra9.ErgsseccmA),np.array(f_tra10.ErgsseccmA),np.array(f_tra11.ErgsseccmA),np.array(f_tra12.ErgsseccmA),np.array(f_tra13.ErgsseccmA),np.array(f_tra14.ErgsseccmA),np.array(f_tra15.ErgsseccmA)])\n",
    "f_tra1_fum0=[10**(i-8) * u.erg/(u.s * u.cm**2 *u.Angstrom) for i in f_traErgsseccmA]\n",
    "f_traAng=np.array([np.array(f_tra0.Angstroem / 10000),np.array(f_tra1.Angstroem / 10000),np.array(f_tra2.Angstroem / 10000),np.array(f_tra3.Angstroem / 10000),np.array(f_tra4.Angstroem / 10000),np.array(f_tra5.Angstroem / 10000),np.array(f_tra6.Angstroem / 10000),np.array(f_tra7.Angstroem / 10000),np.array(f_tra8.Angstroem / 10000),np.array(f_tra9.Angstroem / 10000),np.array(f_tra10.Angstroem / 10000),np.array(f_tra11.Angstroem / 10000),np.array(f_tra12.Angstroem / 10000),np.array(f_tra13.Angstroem / 10000),np.array(f_tra14.Angstroem / 10000),np.array(f_tra15.Angstroem / 10000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3520984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interp the star flux based on the wavelength of albedo\n",
    "f_ref_earth_fit =[]\n",
    "for i in range(len(f_tra1_fum0)):\n",
    "    f_ref_earth_fit.append(np.interp(absor1.nm[:1079300]/1000,f_traAng[i],f_tra1_fum0[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09b2763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the unit from J/ s cm^2 ans to W / m^2\n",
    "Flux_surface = []\n",
    "for i in range(len(f_ref_earth_fit)):\n",
    "    Flux_surface.append((f_ref_earth_fit[i][1:] * np.diff(absor1.nm[:1079300]/1000) * u.um).to(u.W/u.m**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35945d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delution factor\n",
    "df = (pts.SRadiusSun * const.R_sun / (pts.SMAAU * const.au))**2\n",
    "\n",
    "#flux of star on planet\n",
    "f_ref_p = np.array(Flux_surface)* np.array(df).reshape(-1,1)\n",
    "\n",
    "#flux of planet on earth, without abd\n",
    "f_ref_earth = f_ref_p* np.pi * np.array(((pts.RadiusEar * const.R_earth)**2 / (4 * np.pi * (pts.DistancePC * const.pc)**2))).reshape(-1,1)\n",
    "f_ref_earth_fit = f_ref_earth \n",
    "\n",
    "modern_earth_abd_fit = np.array(my_list_norabd[1:1079300])*0.3\n",
    "f_ref_planet_earth_fit = [i * modern_earth_abd_fit for i in f_ref_earth_fit] #w/m2\n",
    "\n",
    "#total flux of planet on earth\n",
    "flux_tot = np.array(f_ref_planet_earth_fit)+np.array(Flux_tbd_planet_earth)\n",
    "\n",
    "#target band\n",
    "wl_um_check = np.linspace(3.0,5.6,2600) * u.um\n",
    "\n",
    "#total flux after bin\n",
    "Range_min=wl_um_check-np.diff(wl_um_check)[1]*0.5\n",
    "Range_max=wl_um_check+np.diff(wl_um_check)[1]*0.5\n",
    "bin_range=[]\n",
    "for i in range(len(wl_um_check)):\n",
    "    bin_range.append(np.where((absor1.nm[1:1079300]/1000 < Range_max[i]/u.um) & (absor1.nm[1:1079300]/1000 > Range_min[i]/u.um)))\n",
    "flux_bin = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]#W/m**2\n",
    "for a in range(len(flux_tot)):\n",
    "    for i in range(len(bin_range)):\n",
    "        flux_bin[a].append(np.sum(flux_tot[a][bin_range[i]]))\n",
    "        \n",
    "\n",
    "# NO GAS flux\n",
    "#blackbody\n",
    "my_list_Noabd = alb_nogas*0+1\n",
    "tbd_planet_no=[]\n",
    "\n",
    "for i in range(len(pts.Teq)):\n",
    "    tbd_planet_no.append(np.array(my_list_Noabd[:1079300]) * 2 * const.h *const.c**2 / ((wl_um2)**5 * (np.e**(const.c * const.h / (wl_um2 *const.k_B * pts.Teq[i] * u.K)) - 1)))\n",
    "\n",
    "\n",
    "tbd_planet_earth_no = []\n",
    "for i in range(len(tbd_planet_no)):\n",
    "    tbd_planet_earth_no.append((tbd_planet_no[i] * ste[i]).to(u.erg/(u.s * u.cm**2 * u.um)))\n",
    "Flux_tbd_planet_earth_no =[]\n",
    "for i in range(len(tbd_planet_earth_no)):\n",
    "    Flux_tbd_planet_earth_no.append((tbd_planet_earth_no[i][1:] * np.diff(wl_um2)).to(u.W/u.m**2))\n",
    "##\n",
    "#reflection flux\n",
    "modern_earth_abd_fit_no = np.array(my_list_norabd[1:1079300])*0 + 0.3 # a 0.3 albedo assumed\n",
    "f_ref_planet_earth_fit_no = [i * modern_earth_abd_fit_no for i in f_ref_earth_fit]\n",
    "\n",
    "#total flux and flux bin\n",
    "flux_tot_no = np.array(f_ref_planet_earth_fit_no)+np.array(Flux_tbd_planet_earth_no)\n",
    "\n",
    "flux_bin_no = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]#W/m**2\n",
    "for a in range(len(flux_tot_no)):\n",
    "    for i in range(len(bin_range)):\n",
    "        flux_bin_no[a].append(np.sum(flux_tot_no[a][bin_range[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e01c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04d32c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.nddata import NDData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da8754ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy of photon\n",
    "h = const.h\n",
    "wl_um = np.linspace(3.0,5.6,2600) * u.um\n",
    "c = const.c #unit:m/s\n",
    "wl_m = (wl_um).to(u.m)\n",
    "pe_1 = h * c / (wl_um).to(u.um)\n",
    "wl_um_check = np.linspace(3.0,5.6,2600)*u.um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5410217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delution factor of star on earth\n",
    "df_s = (pts.SRadiusSun * const.R_sun / (pts.DistancePC * const.pc))**2\n",
    "\n",
    "# flux of star on earth and bin\n",
    "f_s = np.array(Flux_surface)*np.array(df_s).reshape(-1,1)\n",
    "f_s_fit = f_s \n",
    "flux_bin_s = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]#W/m**2\n",
    "for a in range(len(f_s_fit)):\n",
    "    for i in range(len(bin_range)):\n",
    "        flux_bin_s[a].append(np.sum(f_s_fit[a][bin_range[i]])) #more resolution, more data points, less photon number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ad3f2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1000 # here we set Reseolution = 1000\n",
    "t = 60*26*u.s # here we set time = 1h with unit:s\n",
    "S = (3930 * 0.5)**2 * np.pi *u.cm * u.cm #here we set diameter as the first diameter with unit:cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0ddd82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#photon number of star on ELT\n",
    "pn_0_elt=(np.array(flux_bin_s[0])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_1_elt=(np.array(flux_bin_s[1])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_2_elt=(np.array(flux_bin_s[2])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_3_elt=(np.array(flux_bin_s[3])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_4_elt=(np.array(flux_bin_s[4])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_5_elt=(np.array(flux_bin_s[5])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_6_elt=(np.array(flux_bin_s[6])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_7_elt=(np.array(flux_bin_s[7])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_8_elt=(np.array(flux_bin_s[8])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_9_elt=(np.array(flux_bin_s[9])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_10_elt=(np.array(flux_bin_s[10])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_11_elt=(np.array(flux_bin_s[11])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_12_elt=(np.array(flux_bin_s[12])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_13_elt=(np.array(flux_bin_s[13])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_14_elt=(np.array(flux_bin_s[14])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_15_elt=(np.array(flux_bin_s[15])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9bec2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_1e=[i * u.W/u.m**2 for i in flux_bin] #energy of photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f5ce9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#photon number of planet on ELT\n",
    "pn_0e_elt=(np.array(phe_1e[0])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_1e_elt=(np.array(phe_1e[1])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_2e_elt=(np.array(phe_1e[2])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_3e_elt=(np.array(phe_1e[3])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_4e_elt=(np.array(phe_1e[4])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_5e_elt=(np.array(phe_1e[5])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_6e_elt=(np.array(phe_1e[6])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_7e_elt=(np.array(phe_1e[7])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_8e_elt=(np.array(phe_1e[8])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_9e_elt=(np.array(phe_1e[9])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_10e_elt=(np.array(phe_1e[10])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_11e_elt=(np.array(phe_1e[11])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_12e_elt=(np.array(phe_1e[12])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_13e_elt=(np.array(phe_1e[13])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_14e_elt=(np.array(phe_1e[14])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_15e_elt=(np.array(phe_1e[15])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248dacf",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f7f9249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sky\n",
    "pe_1 = h * c / (wl_um).to(u.um) #energy of photon\n",
    "\n",
    "# solid angle for ELT, working at 2um\n",
    "ste_atmo2 = ((2*u.um / (39.3*u.m))**2 * u.steradian).to(u.arcsec**2) #ste\n",
    "\n",
    "#sky emission\n",
    "n_s = pd.read_csv('/Users/huihaoz/Documents/reseatch/radiance.dat.txt', comment = '#', delimiter='\\s+')\n",
    "wl_ns = (np.array(n_s[\"wavelength(nm)\"])*u.nm).to(u.um)\n",
    "bri_surface = np.array(n_s[\"ph/sec/arcsec^2/um/m^2\"])*u.ph/(u.m**2 * u.s * u.arcsec**2 *u.um)\n",
    "pe_ns = (h * c /wl_ns).to(u.J)/u.ph\n",
    "st = ste_atmo2\n",
    "\n",
    "#sky flux on earth\n",
    "f_n_s = ((bri_surface *pe_ns).to(u.W/(u.m**2 * u.um * u.steradian))*st*np.diff(wl_ns)[1]).to(u.W/u.m**2)\n",
    "bin_range_n = []\n",
    "\n",
    "for i in range(len(wl_um)):\n",
    "    bin_range_n.append(np.where((wl_ns/u.um < Range_max[i]/u.um) & (wl_ns/u.um > Range_min[i]/u.um)))\n",
    "    \n",
    "#flux of sky after bin\n",
    "f_r_n=[]\n",
    "for i in range(len(bin_range_n)):\n",
    "    f_r_n.append(np.sum(f_n_s[bin_range_n[i]]).value)\n",
    "pe_e = (h * c / wl_um).to(u.J)\n",
    "noif_sky =(np.array(f_r_n)*u.W/u.m**2)\n",
    "\n",
    "#photon number of sky on ELT\n",
    "pnsky_1_elt=(noif_sky*S*t*wl_um/(pe_1*u.um)).to(u.m/u.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "05b0f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sky transmission\n",
    "trans = pd.read_csv('/Users/huihaoz/Documents/reseatch/transmission.dat.txt', comment = '#', delimiter='\\s+')\n",
    "\n",
    "#interp with the wavelength we used\n",
    "trans_use = np.interp(wl_um/u.um,trans[\"wavelength(nm)\"]/1000,trans[\"transmission\"])\n",
    "\n",
    "pn_pla_elt=[pn_0e_elt,pn_1e_elt,pn_2e_elt,pn_3e_elt,pn_4e_elt,pn_5e_elt,pn_6e_elt,pn_7e_elt,pn_8e_elt,pn_9e_elt,pn_10e_elt,pn_11e_elt,pn_12e_elt,pn_13e_elt,pn_14e_elt,pn_15e_elt]\n",
    "pn_star_elt=[pn_0_elt,pn_1_elt,pn_2_elt,pn_3_elt,pn_4_elt,pn_5_elt,pn_6_elt,pn_7_elt,pn_8_elt,pn_9_elt,pn_10_elt,pn_11_elt,pn_12_elt,pn_13_elt,pn_14_elt,pn_15_elt]\n",
    "\n",
    "#sky transmission normalized\n",
    "nor_trans = np.random.normal(trans_use,0.001*trans_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "be279303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/5300-env/lib/python3.9/site-packages/astropy/units/quantity.py:666: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#noise, includ of dectector(sky, planet, star) and the remove section and transmission\n",
    "c_1 = 10**(-4)\n",
    "n_0 = ((((pn_0e_elt+2*c_1*pn_0_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_0e_elt**2)**(1/2)\n",
    "n_1 = ((((pn_1e_elt+2*c_1*pn_1_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_1e_elt**2)**(1/2)\n",
    "n_2 = ((((pn_2e_elt+2*c_1*pn_2_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_2e_elt**2)**(1/2)\n",
    "n_3 = ((((pn_3e_elt+2*c_1*pn_3_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_3e_elt**2)**(1/2)\n",
    "n_4 = ((((pn_4e_elt+2*c_1*pn_4_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_4e_elt**2)**(1/2)\n",
    "n_5 = ((((pn_5e_elt+2*c_1*pn_5_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_5e_elt**2)**(1/2)\n",
    "n_6 = ((((pn_6e_elt+2*c_1*pn_6_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_6e_elt**2)**(1/2)\n",
    "n_7 = ((((pn_7e_elt+2*c_1*pn_7_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_7e_elt**2)**(1/2)\n",
    "n_8 = ((((pn_8e_elt+2*c_1*pn_8_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_8e_elt**2)**(1/2)\n",
    "n_9 = ((((pn_9e_elt+2*c_1*pn_9_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_9e_elt**2)**(1/2)\n",
    "n_10 = ((((pn_10e_elt+2*c_1*pn_10_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_10e_elt**2)**(1/2)\n",
    "n_11 = ((((pn_11e_elt+2*c_1*pn_11_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_11e_elt**2)**(1/2)\n",
    "n_12 = ((((pn_12e_elt+2*c_1*pn_12_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_12e_elt**2)**(1/2)\n",
    "n_13 = ((((pn_13e_elt+2*c_1*pn_13_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_13e_elt**2)**(1/2)\n",
    "n_14 = ((((pn_14e_elt+2*c_1*pn_14_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_14e_elt**2)**(1/2)\n",
    "n_15 = ((((pn_15e_elt+2*c_1*pn_15_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.01)**2 * pn_15e_elt**2)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8c43a",
   "metadata": {},
   "source": [
    "# No gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cb40df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above but with albedo of no biosignature gas\n",
    "phe_1e_nogas=[i * u.W/u.m**2 for i in flux_bin_no] #changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9078cb23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pn_0e_elt_nogas=(np.array(phe_1e_nogas[0])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_1e_elt_nogas=(np.array(phe_1e_nogas[1])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_2e_elt_nogas=(np.array(phe_1e_nogas[2])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_3e_elt_nogas=(np.array(phe_1e_nogas[3])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_4e_elt_nogas=(np.array(phe_1e_nogas[4])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_5e_elt_nogas=(np.array(phe_1e_nogas[5])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_6e_elt_nogas=(np.array(phe_1e_nogas[6])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_7e_elt_nogas=(np.array(phe_1e_nogas[7])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_8e_elt_nogas=(np.array(phe_1e_nogas[8])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_9e_elt_nogas=(np.array(phe_1e_nogas[9])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_10e_elt_nogas=(np.array(phe_1e_nogas[10])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_11e_elt_nogas=(np.array(phe_1e_nogas[11])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_12e_elt_nogas=(np.array(phe_1e_nogas[12])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_13e_elt_nogas=(np.array(phe_1e_nogas[13])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_14e_elt_nogas=(np.array(phe_1e_nogas[14])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)\n",
    "pn_15e_elt_nogas=(np.array(phe_1e_nogas[15])*u.W/u.m**2 *S*t/(pe_1)).to(u.m/u.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "09fa1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dn = np.array([pn_0e_elt_nogas-pn_0e_elt,pn_1e_elt_nogas-pn_1e_elt,pn_2e_elt_nogas-pn_2e_elt,pn_3e_elt_nogas-pn_3e_elt,pn_4e_elt_nogas-pn_4e_elt,pn_5e_elt_nogas-pn_5e_elt,pn_6e_elt_nogas-pn_6e_elt,pn_7e_elt_nogas-pn_7e_elt,pn_8e_elt_nogas-pn_8e_elt,pn_9e_elt_nogas-pn_9e_elt,pn_10e_elt_nogas-pn_10e_elt,pn_11e_elt_nogas-pn_11e_elt,pn_12e_elt_nogas-pn_12e_elt,pn_13e_elt_nogas-pn_13e_elt,pn_14e_elt_nogas-pn_14e_elt,pn_15e_elt_nogas-pn_15e_elt])\n",
    "dnr = np.array([n_0,n_1,n_2,n_3,n_4,n_5,n_6,n_7,n_8,n_9,n_10,n_11,n_12,n_13,n_14,n_15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a20b3",
   "metadata": {},
   "source": [
    "# OK, all data prepared(above)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e404c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the feature wavelength\n",
    "h2o_f=(0.3-0.3*(absor1.albH2O[:1079300]/alb_nogas[:1079300]))\n",
    "co2_f=(0.3-0.3*(absor1.albco2[:1079300]/alb_nogas[:1079300]))\n",
    "ch4_f=(0.3-0.3*(absor1.albch4[:1079300]/alb_nogas[:1079300]))\n",
    "o2_f=(0.3-0.3*(absor1.albo2[:1079300]/alb_nogas[:1079300]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1f13b",
   "metadata": {},
   "source": [
    "O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c7874597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a Python List into Chunks using For Loops\n",
    "# find the envolop albedo (no o2)\n",
    "our_list = np.array(o2_f)\n",
    "chunked_list = list()\n",
    "chunk_size = 251*5*2\n",
    "for i in range(0, len(our_list), chunk_size):\n",
    "    chunked_list.append(our_list[i:i+chunk_size])\n",
    "    \n",
    "our_listwl = np.array(absor1.nm[:1079300] / 1000)\n",
    "chunked_listwl = list()\n",
    "chunk_sizewl = 251*5*2\n",
    "for i in range(0, len(our_listwl), chunk_sizewl):\n",
    "    chunked_listwl.append(our_listwl[i:i+chunk_sizewl])\n",
    "    \n",
    "y_fit_index = np.linspace(0,429,430,dtype = int)\n",
    "wl_fit_index = [np.argmax(chunked_list[i]) for i in y_fit_index] #just for check\n",
    "\n",
    "pn_fit_non = [max(chunked_list[i]) for i in y_fit_index]\n",
    "wl_fit_non = [chunked_listwl[i][np.argmax(chunked_list[i])] for i in y_fit_index]\n",
    "interp_o2 = np.interp(wl_um/u.um,wl_fit_non,np.array(pn_fit_non))\n",
    "baseline_feat = absor1.albo2[300000]*0.5*0.5\n",
    "ind_o2 = np.where((interp_o2>0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9339ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a Python List into Chunks using For Loops\n",
    "# find the envolop albedo (no h2o)\n",
    "our_list = np.array(h2o_f)\n",
    "chunked_list = list()\n",
    "chunk_size = 251*5*2\n",
    "for i in range(0, len(our_list), chunk_size):\n",
    "    chunked_list.append(our_list[i:i+chunk_size])\n",
    "    \n",
    "our_listwl = np.array(absor1.nm[:1079300] / 1000)\n",
    "chunked_listwl = list()\n",
    "chunk_sizewl = 251*5*2\n",
    "for i in range(0, len(our_listwl), chunk_sizewl):\n",
    "    chunked_listwl.append(our_listwl[i:i+chunk_sizewl])\n",
    "    \n",
    "y_fit_index = np.linspace(0,429,430,dtype = int)\n",
    "wl_fit_index = [np.argmax(chunked_list[i]) for i in y_fit_index] #just for check\n",
    "\n",
    "pn_fit_non = [max(chunked_list[i]) for i in y_fit_index]\n",
    "wl_fit_non = [chunked_listwl[i][np.argmax(chunked_list[i])] for i in y_fit_index]\n",
    "interp_h2o = np.interp(wl_um/u.um,wl_fit_non,np.array(pn_fit_non))\n",
    "ind_h2o = np.where((interp_h2o>0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b24745bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a Python List into Chunks using For Loops\n",
    "# find the envolop albedo (no ch4)\n",
    "our_list = np.array(ch4_f)\n",
    "chunked_list = list()\n",
    "chunk_size = 251*5*2\n",
    "for i in range(0, len(our_list), chunk_size):\n",
    "    chunked_list.append(our_list[i:i+chunk_size])\n",
    "    \n",
    "our_listwl = np.array(absor1.nm[:1079300] / 1000)\n",
    "chunked_listwl = list()\n",
    "chunk_sizewl = 251*5*2\n",
    "for i in range(0, len(our_listwl), chunk_sizewl):\n",
    "    chunked_listwl.append(our_listwl[i:i+chunk_sizewl])\n",
    "    \n",
    "y_fit_index = np.linspace(0,429,430,dtype = int)\n",
    "wl_fit_index = [np.argmax(chunked_list[i]) for i in y_fit_index] #just for check\n",
    "\n",
    "pn_fit_non = [max(chunked_list[i]) for i in y_fit_index]\n",
    "wl_fit_non = [chunked_listwl[i][np.argmax(chunked_list[i])] for i in y_fit_index]\n",
    "interp_ch4 = np.interp(wl_um/u.um,wl_fit_non,np.array(pn_fit_non))\n",
    "ind_ch4 = np.where((interp_ch4>0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "efc32027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a Python List into Chunks using For Loops\n",
    "# find the envolop albedo (no co2)\n",
    "our_list = np.array(co2_f)\n",
    "chunked_list = list()\n",
    "chunk_size = 251*5*2\n",
    "for i in range(0, len(our_list), chunk_size):\n",
    "    chunked_list.append(our_list[i:i+chunk_size])\n",
    "    \n",
    "our_listwl = np.array(absor1.nm[:1079300] / 1000)\n",
    "chunked_listwl = list()\n",
    "chunk_sizewl = 251*5*2\n",
    "for i in range(0, len(our_listwl), chunk_sizewl):\n",
    "    chunked_listwl.append(our_listwl[i:i+chunk_sizewl])\n",
    "    \n",
    "y_fit_index = np.linspace(0,429,430,dtype = int)\n",
    "wl_fit_index = [np.argmax(chunked_list[i]) for i in y_fit_index] #just for check\n",
    "\n",
    "pn_fit_non = [max(chunked_list[i]) for i in y_fit_index]\n",
    "wl_fit_non = [chunked_listwl[i][np.argmax(chunked_list[i])] for i in y_fit_index]\n",
    "interp_co2 = np.interp(wl_um/u.um,wl_fit_non,np.array(pn_fit_non))\n",
    "ind_co2 = np.where((interp_co2>0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "22b1b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find wavelength range of them, remove the interval of overleap\n",
    "lisco2 = ind_co2[0].tolist()\n",
    "lish2o = ind_h2o[0].tolist()\n",
    "liso2 = ind_o2[0].tolist()\n",
    "lisch4 = ind_ch4[0].tolist()\n",
    "set1 = set(lisco2)\n",
    "set2 = set(lish2o)\n",
    "set3 = set(liso2)\n",
    "set4 = set(lisch4)\n",
    "common = set1 & set2 | set1 & set3 | set1 & set4 | set2 & set3 | set2 & set4 | set3 & set4\n",
    "\n",
    "set1 -= common\n",
    "set2 -= common\n",
    "set3 -= common\n",
    "set4 -= common\n",
    "\n",
    "indco2 = list(set1)\n",
    "indh2o = list(set2)\n",
    "indo2 = list(set3)\n",
    "indch4 = list(set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a6193068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the total feature wavelength of atmosphere\n",
    "indtotno = indco2+ indh2o + indo2 + indch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "43697343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find snr of o2\n",
    "snr_o2_total=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for a in range(16):\n",
    "    snr_o2_total[a].append(np.sum((dn[a][indo2]/dnr[a][indo2])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "951ef41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0]]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_o2_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35336700",
   "metadata": {},
   "source": [
    "H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7f524927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find snr of h2o\n",
    "snr_h2o_total=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for a in range(16):\n",
    "    snr_h2o_total[a].append(np.sum((dn[a][indh2o]/dnr[a][indh2o])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "62381cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.027291208057662362],\n",
       " [0.11678773468708074],\n",
       " [3.3082140598901786],\n",
       " [1.4629002427327489],\n",
       " [0.1446386133188686],\n",
       " [4.166418476642716],\n",
       " [0.29158451749937325],\n",
       " [0.08296575268742193],\n",
       " [0.30118979510012744],\n",
       " [27.01465354230896],\n",
       " [0.4202876564926711],\n",
       " [0.4511215629022707],\n",
       " [0.061003694890701586],\n",
       " [0.35730000132245066],\n",
       " [0.010765118038515351],\n",
       " [0.001584450142676875]]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_h2o_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4561a8",
   "metadata": {},
   "source": [
    "CH4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c438462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find snr of ch4\n",
    "snr_ch4_total=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for a in range(16):\n",
    "    snr_ch4_total[a].append(np.sum((dn[a][indch4]/dnr[a][indch4])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e1b14158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.08016174125141409],\n",
       " [0.3117304205158674],\n",
       " [2.3719336735525722],\n",
       " [1.32124524009851],\n",
       " [0.29140999953896396],\n",
       " [2.380865447887303],\n",
       " [0.4374114371019228],\n",
       " [0.1902661029284005],\n",
       " [0.6746533749959388],\n",
       " [17.523802822961965],\n",
       " [0.9477418809628126],\n",
       " [0.6530643414957289],\n",
       " [0.18653095941921144],\n",
       " [0.6017216790347935],\n",
       " [0.04097927596387544],\n",
       " [0.006144046814957534]]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_ch4_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a3fa4",
   "metadata": {},
   "source": [
    "CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "882f8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find snr of co2\n",
    "snr_co2_total=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for a in range(16):\n",
    "    snr_co2_total[a].append(np.sum((dn[a][indco2]/dnr[a][indco2])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3798046d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.004152249143600779],\n",
       " [0.022170301008120896],\n",
       " [1.3040626413870355],\n",
       " [0.5517821322534346],\n",
       " [0.03833981178875845],\n",
       " [1.6311895154923401],\n",
       " [0.09585316235946988],\n",
       " [0.01776305638926862],\n",
       " [0.07847128829433557],\n",
       " [12.055831589077318],\n",
       " [0.11091558157648533],\n",
       " [0.15143979879653663],\n",
       " [0.009250116978543273],\n",
       " [0.11082771968635835],\n",
       " [0.0016718169270556968],\n",
       " [0.00021658349788340243]]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_co2_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bb4f430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the snr of atmosphere total\n",
    "Total_modern = (np.array(snr_ch4_total)**2+np.array(snr_co2_total)**2+np.array(snr_h2o_total)**2+np.array(snr_o2_total)**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a13a3aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.47818139e-02],\n",
       "       [3.33626666e-01],\n",
       "       [4.27445072e+00],\n",
       "       [2.04700504e+00],\n",
       "       [3.27582138e-01],\n",
       "       [5.06836684e+00],\n",
       "       [5.34357675e-01],\n",
       "       [2.08326744e-01],\n",
       "       [7.42987357e-01],\n",
       "       [3.43834007e+01],\n",
       "       [1.04266900e+00],\n",
       "       [8.08045612e-01],\n",
       "       [1.96470899e-01],\n",
       "       [7.08530206e-01],\n",
       "       [4.24026390e-02],\n",
       "       [6.34875594e-03]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_modern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a3c47",
   "metadata": {},
   "source": [
    "## list the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7448fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts[\"SNR_o2\"]=np.array(snr_o2_total)\n",
    "pts[\"SNR_ch4\"]=np.array(snr_ch4_total)\n",
    "pts[\"SNR_h2o\"]=np.array(snr_h2o_total)\n",
    "pts[\"SNR_co2\"]=np.array(snr_co2_total)\n",
    "pts[\"SNR_total\"]=np.array(Total_modern)\n",
    "#pts[\"NO_OVER\"]=np.array(snr_total)\n",
    "pts[\"mag\"]=mag_pt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "33cfa17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006348755935659678,\n",
       " 0.04240263903042142,\n",
       " 0.08478181391463509,\n",
       " 0.19647089931154194,\n",
       " 0.2083267438780712,\n",
       " 0.3275821384967465,\n",
       " 0.33362666604324387,\n",
       " 0.5343576750522281,\n",
       " 0.7085302064247877,\n",
       " 0.7429873566571913,\n",
       " 0.8080456121458571,\n",
       " 1.0426690047025862,\n",
       " 2.0470050381336757,\n",
       " 4.274450723829787,\n",
       " 5.068366841390385,\n",
       " 34.38340074357437]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts[['Planet','SNR_total']].sort_values(by=['SNR_total'])['SNR_total'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8d4518f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6t/cpjtlkn10wv603vnph9nr3sh0000gn/T/ipykernel_39429/1026330911.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  SNR_table.to_latex()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\\\begin{tabular}{llrrrrr}\\n\\\\toprule\\n{} &              Planet &  SNR\\\\_total &  SNR\\\\_h2o &  SNR\\\\_ch4 &  SNR\\\\_co2 &  SNR\\\\_o2 \\\\\\\\\\n\\\\midrule\\n9  &            GJ 887 b &      34.38 &    27.01 &    17.52 &    12.06 &     0.0 \\\\\\\\\\n5  &            GJ 411 b &       5.07 &     4.17 &     2.38 &     1.63 &     0.0 \\\\\\\\\\n2  &           GJ 15 A b &       4.27 &     3.31 &     2.37 &     1.30 &     0.0 \\\\\\\\\\n3  &            GJ 251 b &       2.05 &     1.46 &     1.32 &     0.55 &     0.0 \\\\\\\\\\n10 &       Proxima Cen b &       1.04 &     0.42 &     0.95 &     0.11 &     0.0 \\\\\\\\\\n11 &          Ross 128 b &       0.81 &     0.45 &     0.65 &     0.15 &     0.0 \\\\\\\\\\n8  &            GJ 682 b &       0.74 &     0.30 &     0.67 &     0.08 &     0.0 \\\\\\\\\\n13 &         Wolf 1061 c &       0.71 &     0.36 &     0.60 &     0.11 &     0.0 \\\\\\\\\\n6  &            GJ 625 b &       0.53 &     0.29 &     0.44 &     0.10 &     0.0 \\\\\\\\\\n1  &           GJ 1061 d &       0.33 &     0.12 &     0.31 &     0.02 &     0.0 \\\\\\\\\\n4  &            GJ 273 b &       0.33 &     0.14 &     0.29 &     0.04 &     0.0 \\\\\\\\\\n7  &          GJ 667 C c &       0.21 &     0.08 &     0.19 &     0.02 &     0.0 \\\\\\\\\\n12 &  Teegarden's Star c &       0.20 &     0.06 &     0.19 &     0.01 &     0.0 \\\\\\\\\\n0  &           GJ 1002 c &       0.08 &     0.03 &     0.08 &     0.00 &     0.0 \\\\\\\\\\n14 &        TRAPPIST-1 e &       0.04 &     0.01 &     0.04 &     0.00 &     0.0 \\\\\\\\\\n15 &        TRAPPIST-1 h &       0.01 &     0.00 &     0.01 &     0.00 &     0.0 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\""
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNR_table  = pts[['Planet','SNR_total','SNR_h2o','SNR_ch4','SNR_co2','SNR_o2']].sort_values(by='SNR_total',ascending=False).round(2)\n",
    "#pts[['Planet','SNR_total']]\n",
    "SNR_table.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6aea10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Planet</th>\n",
       "      <th>SNR_total</th>\n",
       "      <th>SNR_h2o</th>\n",
       "      <th>SNR_ch4</th>\n",
       "      <th>SNR_co2</th>\n",
       "      <th>SNR_o2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GJ 887 b</td>\n",
       "      <td>34.38</td>\n",
       "      <td>27.01</td>\n",
       "      <td>17.52</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GJ 411 b</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.17</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GJ 15 A b</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GJ 251 b</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Proxima Cen b</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ross 128 b</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GJ 682 b</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wolf 1061 c</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GJ 625 b</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GJ 1061 d</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GJ 273 b</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GJ 667 C c</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Teegarden's Star c</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GJ 1002 c</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TRAPPIST-1 e</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRAPPIST-1 h</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Planet  SNR_total  SNR_h2o  SNR_ch4  SNR_co2  SNR_o2\n",
       "9             GJ 887 b      34.38    27.01    17.52    12.06     0.0\n",
       "5             GJ 411 b       5.07     4.17     2.38     1.63     0.0\n",
       "2            GJ 15 A b       4.27     3.31     2.37     1.30     0.0\n",
       "3             GJ 251 b       2.05     1.46     1.32     0.55     0.0\n",
       "10       Proxima Cen b       1.04     0.42     0.95     0.11     0.0\n",
       "11          Ross 128 b       0.81     0.45     0.65     0.15     0.0\n",
       "8             GJ 682 b       0.74     0.30     0.67     0.08     0.0\n",
       "13         Wolf 1061 c       0.71     0.36     0.60     0.11     0.0\n",
       "6             GJ 625 b       0.53     0.29     0.44     0.10     0.0\n",
       "1            GJ 1061 d       0.33     0.12     0.31     0.02     0.0\n",
       "4             GJ 273 b       0.33     0.14     0.29     0.04     0.0\n",
       "7           GJ 667 C c       0.21     0.08     0.19     0.02     0.0\n",
       "12  Teegarden's Star c       0.20     0.06     0.19     0.01     0.0\n",
       "0            GJ 1002 c       0.08     0.03     0.08     0.00     0.0\n",
       "14        TRAPPIST-1 e       0.04     0.01     0.04     0.00     0.0\n",
       "15        TRAPPIST-1 h       0.01     0.00     0.01     0.00     0.0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNR_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440e95d",
   "metadata": {},
   "source": [
    "# GJ 887 b\n",
    "\n",
    "run 1 first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c487e9",
   "metadata": {},
   "source": [
    "# check contrast form 10-3 to 10-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_9_3=((((pn_9e_elt+2* 10**(-3) *pn_9_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.001)**2 * pn_9e_elt**2)**(1/2)\n",
    "n_9_4=((((pn_9e_elt+2* 10**(-4) *pn_9_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.001)**2 * pn_9e_elt**2)**(1/2)\n",
    "n_9_6=((((pn_9e_elt+2* 10**(-6) *pn_9_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.001)**2 * pn_9e_elt**2)**(1/2)\n",
    "n_9_5=((((pn_9e_elt+2* 10**(-5) *pn_9_elt)*trans_use+2*pnsky_1_elt)**(1/2) / nor_trans)**2 + (0.001)**2 * pn_9e_elt**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SNR(h2o) with instrument contrast 10-3:\",np.sum((dn[9][indh2o]/n_9_3[indh2o])**2)**(1/2))\n",
    "print(\"SNR(h2o) with instrument contrast 10-4:\",np.sum((dn[9][indh2o]/n_9_4[indh2o])**2)**(1/2))\n",
    "print(\"SNR(h2o) with instrument contrast 10-5:\",np.sum((dn[9][indh2o]/n_9_5[indh2o])**2)**(1/2))\n",
    "print(\"SNR(h2o) with instrument contrast 10-6:\",np.sum((dn[9][indh2o]/n_9_6[indh2o])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SNR(ch4) with instrument contrast 10-3:\",np.sum((dn[9][indch4]/n_9_3[indch4])**2)**(1/2))\n",
    "print(\"SNR(ch4) with instrument contrast 10-4:\",np.sum((dn[9][indch4]/n_9_4[indch4])**2)**(1/2))\n",
    "print(\"SNR(ch4) with instrument contrast 10-5:\",np.sum((dn[9][indch4]/n_9_5[indch4])**2)**(1/2))\n",
    "print(\"SNR(ch4) with instrument contrast 10-6:\",np.sum((dn[9][indch4]/n_9_6[indch4])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SNR(co2) with instrument contrast 10-3:\",np.sum((dn[9][indco2]/n_9_3[indco2])**2)**(1/2))\n",
    "print(\"SNR(co2) with instrument contrast 10-4:\",np.sum((dn[9][indco2]/n_9_4[indco2])**2)**(1/2))\n",
    "print(\"SNR(co2) with instrument contrast 10-5:\",np.sum((dn[9][indco2]/n_9_5[indco2])**2)**(1/2))\n",
    "print(\"SNR(co2) with instrument contrast 10-6:\",np.sum((dn[9][indco2]/n_9_6[indco2])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab392f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SNR(o2) with instrument contrast 10-3:\",np.sum((dn[9][indo2]/n_9_3[indo2])**2)**(1/2))\n",
    "print(\"SNR(o2) with instrument contrast 10-4:\",np.sum((dn[9][indo2]/n_9_4[indo2])**2)**(1/2))\n",
    "print(\"SNR(o2) with instrument contrast 10-5:\",np.sum((dn[9][indo2]/n_9_5[indo2])**2)**(1/2))\n",
    "print(\"SNR(o2) with instrument contrast 10-6:\",np.sum((dn[9][indo2]/n_9_6[indo2])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SNR(total) with instrument contrast 10-3:\",np.sum((dn[9][indtotno]/n_9_3[indtotno])**2)**(1/2))\n",
    "print(\"SNR(total) with instrument contrast 10-4:\",np.sum((dn[9][indtotno]/n_9_4[indtotno])**2)**(1/2))\n",
    "print(\"SNR(total) with instrument contrast 10-5:\",np.sum((dn[9][indtotno]/n_9_5[indtotno])**2)**(1/2))\n",
    "print(\"SNR(total) with instrument contrast 10-6:\",np.sum((dn[9][indtotno]/n_9_6[indtotno])**2)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b8e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
